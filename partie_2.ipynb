{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2\n",
    "## Adapter un modèle pré-entrainé : fine-tuning, Dataset, régularisation\n",
    "\n",
    "Dans cette seconde partie, nous allons : \n",
    " * Adapter l'architecture d'AlexNet pour un problème de segmentation sémantique d'images satellites,\n",
    " * Créer un torch.utils.data.Dataset adapté à notre application,\n",
    " * Fine-tuner le modèle,\n",
    " * Régulariser le modèle.\n",
    " \n",
    "On utilisera un extrait de l'image RGB à haute résolution spatiale de Houston  [1].\n",
    "\n",
    "Cet extrait peut être téléchargé ici : https://nextcloud.isae.fr/index.php/s/WmjQPyH3g2EK33x\n",
    "\n",
    "[1]  Saurabh Prasad, Bertrand Le Saux, Naoto Yokoya, Ronny Hansch, December 18, 2020, \"2018 IEEE GRSS Data Fusion Challenge – Fusion of Multispectral LiDAR and Hyperspectral Data\", IEEE Dataport, doi: https://dx.doi.org/10.21227/jnh9-nz89. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la bibliothèque rasterio pour caler la vérité terrain sur l'image RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('../data/UH_NAD83_272056_3289689.tif') as img:\n",
    "    window = Window(0, 0, 1000, 1000)\n",
    "    data = img.read(window=window)\n",
    "    \n",
    "with rasterio.open('../data/2018_IEEE_GRSS_DFC_GT_TR.tif') as gt_:\n",
    "    gt = np.zeros(img.shape, dtype=np.uint8)\n",
    "    reproject(\n",
    "        source=gt_.read(1),\n",
    "        destination=gt,\n",
    "        src_transform=gt_.transform,\n",
    "        src_crs=gt_.crs,\n",
    "        dst_transform=img.transform,\n",
    "        dst_crs=img.crs,\n",
    "        resampling=Resampling.nearest)\n",
    "    \n",
    "img = data.transpose(1, 2, 0)\n",
    "gt = gt[:1000, :1000]\n",
    "for i, class_id in enumerate(np.unique(gt)):\n",
    "    gt[class_id == gt] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,10))\n",
    "ax[0].imshow(img)\n",
    "ax1 = ax[1].imshow(gt)\n",
    "fig.colorbar(ax1, ax=ax, shrink=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La vérité terrain est constituée de deux classes : les bâtiments et les routes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du Dataset PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour optimiser un modèle PyTorch par descente de gradient stochastique par batchs, on utilise deux objets :\n",
    " * un torch.utils.data.Dataset pour parcourir les exemples d'apprentissage,\n",
    " * un torch.utils.data.DataLoader pour faire des batchs d'exemples.\n",
    " \n",
    "Si l'on avait des données structurées, on pourrait utiliser un torch.utils.data.TensorDataset comme suit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 8\n",
    "n_examples = 50\n",
    "n_classes = 4\n",
    "\n",
    "data = torch.randn(n_examples, n_features)\n",
    "labels = torch.randint(size=(n_examples, 1), low=1, high=n_classes+1)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(data, labels)\n",
    "print(len(dataset))\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "print(len(data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre cas, les données ne sont pas organisées de cette façon. On souhaiterait en effet utiliser un modèle qui prenne en entrée des patchs de 51 x 51 pixels et qui prédise la classe du pixel central. Pour cela, on va construire notre propre torch.utils.data.Dataset (https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, gt, hyperparams):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: 3D hyperspectral image\n",
    "            gt: 2D array of labels\n",
    "            patch_size: int, size of the spatial neighbourhood\n",
    "            ignored_labels: list of ints, labels to ignore\n",
    "\n",
    "        \"\"\"\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.label = gt\n",
    "        self.patch_size = hyperparams[\"patch_size\"]\n",
    "        self.ignored_labels = set(hyperparams[\"ignored_labels\"])        \n",
    "        self.height = data.shape[0]\n",
    "        self.width = data.shape[1]\n",
    "\n",
    "        mask = np.ones_like(gt)\n",
    "        for l in self.ignored_labels:\n",
    "            mask[gt == l] = 0\n",
    "\n",
    "        x_pos, y_pos = np.nonzero(mask)\n",
    "        p = self.patch_size // 2\n",
    "        if p > 0:\n",
    "            self.indices = np.array(\n",
    "                [\n",
    "                    (x, y)\n",
    "                    for x, y in zip(x_pos, y_pos)\n",
    "                    if x >= p and x < data.shape[0] - p and y >= p and y < data.shape[1] - p\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.indices = np.array(\n",
    "                [\n",
    "                    (x, y)\n",
    "                    for x, y in zip(x_pos, y_pos)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "        self.labels = [self.label[x, y] for x, y in self.indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        # A compléter \n",
    "        ... \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # A compléter\n",
    "        x, y = ... \n",
    "        x1, y1 = x - self.patch_size // 2, y - self.patch_size // 2\n",
    "        x2, y2 = x1 + self.patch_size, y1 + self.patch_size\n",
    "        \n",
    "        # A compléter\n",
    "        data = ...\n",
    "        label = ...\n",
    "\n",
    "        # Copie de data et label dans des npy array\n",
    "        data = np.asarray(np.copy(data).transpose((2, 0, 1)), dtype=\"float32\")\n",
    "        label = np.asarray(np.copy(label), dtype=\"int64\")\n",
    "\n",
    "        # Conversion des npy array en torch.tensor\n",
    "        # A compléter\n",
    "        data = ...\n",
    "        label = ...\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'ignored_labels': [0], 'patch_size': 51}\n",
    "dataset = Dataset(img, gt, hyperparams)\n",
    "\n",
    "# A compléter\n",
    "train_dataset, val_dataset = ... # On souhaite couper le dataset en un set d'apprentissage et un set de validation\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut visualiser un exemple comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patch, label in train_loader:\n",
    "    break\n",
    "fig = plt.figure()\n",
    "plt.imshow(patch[30,:,:,:].transpose(2,0)/256)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning d'un modèle pré-entrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaiterait reprendre le modèle AlexNet, ou plutôt une plus petite version d'AlexNet, qui a un trop grand nombres de paramètres. \n",
    "\n",
    "On va uniquement conserver la première couche de convolution d'AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyAlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_rate=0):\n",
    "        super(TinyAlexNet, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 1, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.Identity()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(4, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "        x = self.features(inputs)\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.features(inputs)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyAlexNet(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = model.to(device) # On charge le modèle sur GPU si elle est disponible\n",
    "pretrained_weights = torch.load('../pretrained_alex_net.pth.tar', \n",
    "                                map_location=device) # on précise le \"device\" sur lequel est le modèle\n",
    "pretrained_weights['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features[0].weight.data = ...\n",
    "model.features[0].bias.data = ...\n",
    "del pretrained_weights # On supprime les poids de la mémoire du GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.features[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features[0].weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On *freeze* les poids de la première couche afin de ne pas les modifier pendant l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.features[0].weight.requires_grad_(False)\n",
    "model.features[0].bias.requires_grad_(False)\n",
    "print(model.features[0].weight.requires_grad, model.features[0].bias.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les hyper-paramètres de la descente de gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "learning_rate = 1e-4\n",
    "best_val = np.inf\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    y_pred, y_true = [], []\n",
    "    for patch, label in tqdm(train_loader):\n",
    "        patch, label = patch.to(device), label.to(device)-1\n",
    "        logits = model(patch)\n",
    "        loss = F.cross_entropy(logits, label)\n",
    "        loss.backward() # Calcul du gradient \n",
    "        optimizer.step() # Mise à jour des paramètres\n",
    "        optimizer.zero_grad() # Mise à zéro du gradient\n",
    "        \n",
    "        y_pred.extend(torch.argmax(logits, dim=-1).cpu())\n",
    "        y_true.extend(label.cpu())\n",
    "          \n",
    "    train_accuracy = accuracy_score(y_pred, y_true)\n",
    "    train_f1 = f1_score(y_pred, y_true)\n",
    "    \n",
    "    y_pred, y_true = [], []\n",
    "    for patch, label in tqdm(val_loader):\n",
    "        patch, label = patch.to(device), label.to(device)-1\n",
    "        with torch.no_grad():\n",
    "            logits = model(patch)\n",
    "        val_loss = F.cross_entropy(logits, label)\n",
    "        \n",
    "        y_pred.extend(torch.argmax(logits, dim=-1).cpu())\n",
    "        y_true.extend(label.cpu())\n",
    "        \n",
    "    val_accuracy = accuracy_score(y_pred, y_true)\n",
    "    val_f1 = f1_score(y_pred, y_true)\n",
    "    \n",
    "    if val_loss.item() < best_val:\n",
    "        best_val = val_loss.item()\n",
    "        torch.save({'epoch': epoch, \n",
    "                    'best_loss': best_val, \n",
    "                    'state_dict': model.state_dict()}, 'best_model.pth.tar')\n",
    "        \n",
    "    print('[Train] \\t Loss: {:.4f} | Accuracy: {:.4f} | F1 score: {:.4f}'.format(\\\n",
    "                                            loss.item(), train_accuracy, train_f1))\n",
    "    print('[Val] \\t Loss: {:.4f} | Accuracy: {:.4f} | F1 score: {:.4f}'.format(\\\n",
    "                                          val_loss.item(), val_accuracy, val_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout d'un terme de régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaiterait pouvoir régulariser notre modèle en pénalisant, soit la norme L1 soit la norme L2, de ses paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization(model, norm=\"L2\"):\n",
    "    # A compléter\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization(model.classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
